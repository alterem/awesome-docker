[返回首页](../README.md)

# AI

此目录用于存放与人工智能相关的项目和工具。

### Stable Diffusion WebUI

Stable Diffusion WebUI 是一个基于 Gradio 库的浏览器界面，用于 Stable Diffusion。它提供了丰富的功能，包括文生图、图生图、图像修复、图像放大等，是目前最流行的AI绘画工具之一。

*   **推荐镜像:** `ghcr.io/cmdr2/stable-diffusion-ui` (或自行构建)
*   **Docker Hub 链接:** [https://hub.docker.com/r/cmdr2/stable-diffusion-ui](https://hub.docker.com/r/cmdr2/stable-diffusion-ui)
*   **GitHub 链接:** [https://github.com/AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)

### ChatGPT Next Web

ChatGPT Next Web 是一个开源的 ChatGPT 网页客户端，支持一键部署，提供美观的用户界面和丰富的功能，如多模型支持、自定义API、Markdown渲染等。

*   **推荐镜像:** `yidadaa/chatgpt-next-web`
*   **Docker Hub 链接:** [https://hub.docker.com/r/yidadaa/chatgpt-next-web](https://hub.docker.com/r/yidadaa/chatgpt-next-web)
*   **GitHub 链接:** [https://github.com/Yidadaa/ChatGPT-Next-Web](https://github.com/Yidadaa/ChatGPT-Next-Web)

### LocalAI

LocalAI 是一个免费、开源的本地推理引擎，兼容 OpenAI API。它允许你在本地运行各种大型语言模型（LLM）、图像生成模型等，无需依赖云服务，保护数据隐私。

*   **推荐镜像:** `go-skynet/local-ai`
*   **Docker Hub 链接:** [https://hub.docker.com/r/go-skynet/local-ai](https://hub.docker.com/r/go-skynet/local-ai)
*   **GitHub 链接:** [https://github.com/mudler/LocalAI](https://github.com/mudler/LocalAI)

### Open-WebUI

Open-WebUI 是一个可扩展的、用户友好的 WebUI，用于与各种大型语言模型（LLM）进行交互，支持 Ollama、OpenAI 等。

*   **推荐镜像:** `ghcr.io/open-webui/open-webui`
*   **Docker Hub 链接:** [https://hub.docker.com/r/open-webui/open-webui](https://hub.docker.com/r/open-webui/open-webui)
*   **GitHub 链接:** [https://github.com/open-webui/open-webui](https://github.com/open-webui/open-webui)

### LobeChat

LobeChat 是一个开源的、高性能的 LLM UI，支持多种模型、TTS、插件等，旨在提供极致的对话体验。

*   **推荐镜像:** `lobehub/lobe-chat`
*   **Docker Hub 链接:** [https://hub.docker.com/r/lobehub/lobe-chat](https://hub.docker.com/r/lobehub/lobe-chat)
*   **GitHub 链接:** [https://github.com/lobehub/lobe-chat](https://github.com/lobehub/lobe-chat)

### Ollama

Ollama 允许你在本地运行大型语言模型。它提供了一个简单的命令行界面和 API，方便用户下载、运行和管理各种开源模型，可以作为本地AI推理的后端。

*   **推荐镜像:** `ollama/ollama`
*   **Docker Hub 链接:** [https://hub.docker.com/r/ollama/ollama](https://hub.docker.com/r/ollama/ollama)
*   **GitHub 链接:** [https://github.com/ollama/ollama](https://github.com/ollama/ollama)

### TritonInferenceServer

NVIDIA Triton Inference Server 是一个开源的推理服务软件，旨在帮助开发者在生产环境中部署和运行各种AI模型。它支持多种框架和模型格式，并提供高性能的推理能力。

*   **推荐镜像:** `nvcr.io/nvidia/tritonserver:latest`
*   **Docker Hub 链接:** [https://ngc.nvidia.com/catalog/containers/nvidia:tritonserver](https://ngc.nvidia.com/catalog/containers/nvidia:tritonserver) (NVIDIA NGC)
*   **GitHub 链接:** [https://github.com/triton-inference-server/server](https://github.com/triton-inference-server/server)